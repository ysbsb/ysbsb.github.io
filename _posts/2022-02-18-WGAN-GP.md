---
layout: post
title: WGAN-GP 논문 리뷰 - Improved Training of Wassertein GANs (NIPS2017)
subtitle: WGAN-GP paper review - Improved Training of Wassertein GANs (NIPS2017)
category: [GAN]
tags: [GAN]
comments: true
use_math: true

---





> [![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fysbsb.github.io%2Fgan%2F2022%2F02%2F18%2FWGAN-GP.html&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
>
> 안녕하세요. 모카의 머신러닝 입니다. 이번 포스팅은 "Improved Training of Wassertein GANs, NIPS 2017"에 대해 리뷰합니다. 영어로 된 논문을 한글로 같이 해석하며 논문에서 의미하는 것이 무엇인지 같이 공부하며 이해하고 활용하실 수 있도록 준비해보았습니다. 

<br>



[Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)

논문에 대한 해석은 간결한 문장으로 표현하려고 합니다. 그림과 표는 모두 해당 논문을 참조하였습니다.

<br>



# Abstract

GAN은 파워풀한 생성 모델이지만, 학습의 불안정성을 겪는다. 최근에 제안된 Wasserstein GAN (WGAN)은 GAN의 안정적인 학습으로 진전했지만, 가끔 아직도 안좋은 샘플들을 생성하거나 수렴에 실패하기도 한다. 우리는 이러한 문제를 바람직하지 않은 behavior로 이끌 수 있는 critic에 Lipschitz constraint를 부과하기 위해 WGAN에서 weight clipping을 사용하기 때문이라고 발견했다. 우리는 가중치를 clipping 하는 것의 대안을 제안한다: critic의 입력에 대해서 gradient의 norm에 패널티를 부여한다. 우리의 방법은 보통의 WGAN보다 좋은 성능을 보이고, 101개의 ResNet과 연속적인 generator의 언어 모델을 포함하여 하이퍼라마티어 튜닝 없이 넓고 다양한  GAN 아키텍쳐의 학습을 안정화 하는 것을 가능하게 한다. 우리는 또한 CIFAR10과 LSUN 데이터셋에서 좋은 퀄리티를 얻었다.

 

# 1. Introduction

Generative Adversarial Networks (GAN)은 생성 모델링을 두개의 네트워크의 게임으로 캐스팅하는 파워풀한 생성 모델의 한 분야이다: generator 네트워크는 몇몇의 노이즈 소스가 주어졌을 때 합성 데이터를 생성하고 discriminator 네트워크는 generator의 출력과 실제 데이터 사이를 구분한다. GAN은 시각적으로 매우 매력적인 샘플들을 생성하지만, 종종 학습하기 어렵고, 주제에서 몇몇의 연구는 학습을 안정화 시키도록 하는 방법을 찾는데 전념했다. 그럼에도 불구하고, 지속적으로 GAN의 학습을 안정화 시키는 것은 아직도 열린 문제로 남아있다.

특히, [1]은 GAN에 의해 최적화되는 value function의 수렴 특성의 분석을 제공한다. Wasserstein GAN (WGAN)이라 부르는 그들의 대안은 원래의 것보다 더 이론적인 특성을 가지고 있는 value function을 생성하도록 Wasserstein distance를 사용한다. WGAN은 discriminator가 작가들은 weight clipping을 통해 부여한, 반드시 1-Lipschitz function의 공간에 있음을 요구한다.

우리의 기여는 다음과 같다:

1. toy dataset에서, 우리는 critic weight clipping이 바람직하지 않은 behavior로 이끌 수 있음을 증명한다.
2. 우리는 같은 문제를 겪지 않는 gradient penalty (WGAN-GP)를 제안한다.
3. 우리는 다양한 GAN 아키텍쳐에서 안정적인 학습과, weight clipping을 넘는 성능 증가, 높은 퀄리티의 이미지 생성, discrete sampling 없이 character-level GAN 언어 모델을 증명한다.

# 2. Background

## 2.1 Generative adversarial networks

GAN의 학습 전략은 두개의 경쟁적인 네트워크 사이의 게임으로 정의된다. generator 네트워크는 노이즈의 소스를 입력 공간으로 맵핑한다. discriminator 네트워크는 생성된 샘플 또는 실제 데이터를 받고 반드시 두개 사이를 구분해야 한다. generator는 안좋은 discriminator를 학습하도록 한다.

공식적으로, generator G와 discriminator D 사이의 게임은 minmax objective이다.

$$
\min _{G} \max _{D} \underset{\boldsymbol{x} \sim \mathbb{P}_{r}}{\mathbb{E}}[\log (D(\boldsymbol{x}))]+\underset{\tilde{\boldsymbol{x}} \sim \mathbb{P}_{g}}{\mathbb{E}}[\log (1-D(\tilde{\boldsymbol{x}}))]
$$

$\mathbb{P}_{r}$은 데이터 분포이고 $\mathbb{P}_{g}$는 암묵적으로 $\tilde{x}=G(z)$, $\boldsymbol{z} \sim p(\boldsymbol{z})$에 의해 정의된 모델의 분포이다. 

만약 discriminator가 각각의 generator 파라미터 업데이트 전에 최적성으로 학습이 된다면, value function을 최소화하는 것은 $\mathbb{P}_{r}$와 $\mathbb{P}_{g}$ 사이의 Jensen-Shannon divergence를 최소화 하는 것과 같지만, 그렇게 하면 판별자가 포화될 때 그래디언트가 사라지는 경우자 종종 있다. 특히, 이 어려움을 우회하는 방법인, $\mathbb{E}_{\tilde{\boldsymbol{x}} \sim \mathbb{P}_{g}}[\log (D(\tilde{\boldsymbol{x}}))]$를 최대화 하는 것을 대신 되어야 한다고 주장한다. 하지만, 심지어 변형된 loss function은 좋은 discriminator 존재에서 잘못 행동되어질 수 있다.

## 2.2 Wasserstein GANs

[2]는 GAN이 전형적으로 최소화 하는 것이 generator의 파라미터에 대해서 잠재적으로 연속적이지 않은 divergence는 학습의 어려움을 이끈다고 주장한다. 그들은 대신에 Earth-Mover (또한 Wasserstein-1이라 불리는 distance $W(q, p)$를 사용했고, 이것은 분포 q를 분포 p로 변형하기 위한 transporting mass의 최소 비용으로 정의되었다. 가벼운 가정하에, $W(q, p)$는 어느곳에서나 연속적이고 거의 모든곳에서 미분가능하다.

WGAN의 value function은 Kantorovich-Rubinstein duality를 사용하여 구성되었다.

$$
\left.\min _{G} \max _{D \in \mathcal{D}} \underset{\boldsymbol{x} \sim \mathbb{P}_{r}}{\mathbb{E}}[D(\boldsymbol{x})]-\underset{\tilde{\boldsymbol{x}} \sim \mathbb{P}_{g}}{\mathbb{E}}[D(\tilde{\boldsymbol{x}}))\right]
$$

$\mathcal{D}$는 1-Lipschitz function의 집합이고 $\mathbb{P}_{g}$는 $\tilde{x}=G(z)$, $\boldsymbol{z} \sim p(\boldsymbol{z})$에 의해 정의된 모델의 분포이다. 이 경우에, 최적의 discriminator 하에, generator 파라미터에 관련된 value function을 최소화 하는 것은 $W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$를 최소화한다.

WGAN의 value function은 입력이 GAN의 대응보다 더 잘 작동하는 gradient를 가지는 critic function의 결과를 얻고 generator의 최적화를 더 쉽게 만든다. 실험적으로, WGAN의 value function은 GAN의 case에 해당되지 않는 샘플 퀄리티와 관련된 것을 보임을 관찰했다.

critic에 Lipschitz constraint를 부과하기 위해서, [2]는 compact space [-c, c]안에 critic의 가중치가 놓여지도록 clip하는 것을 제안한다. 이 constraint를 만족하는 함수의 집합은 c와 critic 아키텍쳐에 의존하는 k를 위한 k-LIpschitz function의 부분집합이다. 다음 secion에서는, 우리는 이러한 접근법의 몇가지 이슈를 증명하고 대안을 제안한다.

## 2.3 Properties of the optimal WGAN critic

WGAN의 critic에서 왜 weight clipping이 문제가 있었는지 이해하고 우리의 접근법을 동기부여 하기 위해서, 우리는 WGAN 프레임워크에서 최적의 critic의 몇가지 특성을 하이라이트 한다.

# 3. Difficulties with weight contraints

우리는 WGAN에서 weight clipping이 최적화 어려움을 이끈다는 것을 발견했고, 심지어 최적화의 성공이 critic이 pathological value surface를 갖게 하는 결과를 이끈다. 우리는 이러한 문제를 아래에 설명했고 이것들의 효과를 증명한다; 하지만 우리는 각각의 것이 실제로 항상 발생한다는 것을 주장하지 않고 이것들은 오직 메커니즘이다.

우리의 실험은 [2]로부터의 weight constraint 특정한 형식을 사용하지만, 우리는 또한 다른 weight constraint도 시도했고 이것들이 비슷한 문제를 보임을 발견했다.

이러한 문제는 어느정도 [2]에서 그들의 모든 실험에 사용된 critic에서 batch normalization과 함께 완화될 수 있다. 하지만 심지어 batch normalization에서도, 우리는 매우 깊은 WGAN critic이 종종 수렴에 실패한다는 것을 관찰했다.

![1](https://user-images.githubusercontent.com/37301677/154640855-9a3f9dba-a32d-46ed-b04f-43e3cbc6b56a.PNG)

## 3.1 Capacity underuse

weight clipping을 통해서 k-Lipschitz constraint를 부과하는 것은 critic을 더 간단한 함수로 편향시킨다. 이전에 Corolalry 1에서 말한데로, 최적의 WGAN critic은 $\mathbb{P}_{r}$과 $\mathbb{P}_{g}$ 아래에 거의 모든 곳에서 unit gradient norm을 가진다; weight-clipping constraint 하에서, 우리는 gradient norm k를 최대화하도록 얻도록 시도하는 우리의 뉴럴 아키텍쳐들이 굉장히 쉬운 함수의 학습으로 마친다는 것을 발견했다.

이것을 증명하기 위해서, 우리는 weight clipping과 함께한 WGAN critic을 몇몇의 toy 분포에 대한 최적성으로 학습했고, generator 분포 $\mathbb{P}_{g}$는 실제 분포 더하기 unit-variance Gaussin noise에서 고정되었다. 우리는 critics의 value surface를 Figure 1a에 그렸다. 우리는 critic에서 batch normalization은 생략했다. 각각의 경우에서, weight clipping과 함께 학습된 critic은 데이터 분포의 더 높은 순간을 무시하고 대신에 모델은 최적화 함수로 매우 간단한 근사를 한다. 반대로, 우리의 방법은 이러한 behavior로부터 겪지 않는다.

## 3.2 Exploding and vanishing gradients

우리는 clipping threshold c의 조심스러운 튜닝 없이 gradient가 vanishing 또는 exploding 하는 결과를 일으키는 weight constraint와 cost function 사이의 상호작용 때문에 WGAN의 최적화 과정은 어렵다고 관찰했다.

이것을 증명하기 위해서, 우리는 clipping threshold c를 다르게 하면서 Swiss Roll toy 데이터셋에서 WGAN을 학습했고, 성공적인 activation의 layer에 대해서 critic loss의 gradient의 norm을 표로 그렸다. generator와 critic 둘 다 batch normalization 없이 12 layer ReLU MLP이다. Figure 1b는 이러한 value들을 보여주고, gradient는 네트워크 안에서 움직일 때 마다 지수적으로 자라거나 decay 된다. 우리는 우리의 방법이 더 복잡한 네트워크의 학습을 허락하면서 사라지거나 폭발하지 않는 더 안정적인 gradient의 결과를 가짐을 찾았다.

![2](https://user-images.githubusercontent.com/37301677/154640860-b97ec4e8-b390-4c33-a31a-969584cff16a.PNG)

# 4. Gradient penalty

우리는 이제 Lipschitz constraint을 부과하는 대안의 방법을 제안한다. 미분가능한 함수는 1-Lipschitz 함수이고 norm과 함께한 gradient가 어디에서나 1이 되고, 그래서 우리는 입력에 대해서 critic의 출력의 gradient norm을 직접적으로 구속하는 것을 고려한다. 다루기 쉬운 문제를 피하기 위해, 우리는 랜덤 샘플 $\hat{\boldsymbol{x}} \sim \mathbb{P}_{\hat{\boldsymbol{x}}}$를 위해 gradient norm에 penalty가 있는 contraint의 부드러운 버전을 부과한다.

$$
L=\underset{\tilde{\boldsymbol{x}} \sim \mathbb{P}_{q}}{\mathbb{E}}[D(\tilde{x})]-\underset{\boldsymbol{x} \sim \mathbb{P}_{r}}{\mathbb{E}}[D(x)]+\lambda \underset{\hat{\boldsymbol{x}} \sim \mathbb{P}_{\hat{\boldsymbol{\phi}}}}{\mathbb{E}}\left[\left(\left\|\nabla_{\hat{\boldsymbol{x}}} D(\hat{x})\right\|_{2}-1\right)^{2}\right]
$$

### Sampling distribution

우리는 $\mathbb{P}_{\hat{x}}$ 샘플링을 데이터 분포 $\mathbb{P}_{r}$과 generator 분포 $\mathbb{P}_{g}$로 부터 샘플된 점 사이의 직선을 따라 uniform하게 정의한다. 이것은 최적의 critic이 $\mathbb{P}_{r}$과 $\mathbb{P}_{g}$로부터의 점 사이를 연결하는 gradient norm 1과 함께 직선을 포함한다는 사실로부터 동기부여 됬다. unit gradient norm constraint을 모든곳에 부과하기는 어려운 일이므로, 단지 이러한 직선을 따라 부과하는 것은 충분에 보이고 실험적으로 좋은 성능을 보이는 것 같다.

### Penalty coefficient

본 논문에서 모든 실험은 lambda=10을 사용했고, 우리는 toy task에서 큰 ImageNet CNN 까지 다양한 아키텍쳐와 데이터셋에서 잘 작동하는 것을 발견했다.

### No critic batch normalization

대부분의 이전의 GAN implementation에서는 학습을 안정화시키기 위해서 generator와 discriminator 둘 다에 batch normalization을 사용하지만, batch normalization은 discriminator의 문제의 형태를 단일 출입력을 단일 출력으로 맵핑하는 것에서 입력의 모든 배치로부터 출력의 배치를 맵핑하는 것으로 변화시킨다. 우리의 패널티가 부과된 학습 목점함수는 우리가 전체의 배치가 아니라 각각의 입력에 독립적으로에 대해서 critic의 gradient의 norm에 패널티를 부과하기 때문에 더이상 이러한 셋팅이 유효하지 않다. 이러한 문제를 해결하기 위해서, 우리는 우리의 모델의 critic에서 batch normalization을 간단하게 생략하고, 이것이 없이 잘 작동하는 것을 찾았다. 우리의 방법은 예시들 사이의 correlation을 도입하지 않는 normalization 방법과 함께 작동한다. 특히, 우리는 batch normalization을 위한 대체로써 layer normalization을 추천한다.

### Two-sided penalty

우리는 gradient의 norm을 1 아래에 두는 대신에 1로 가도록 격려한다. 실험적으로 이것은 최적의 WGAN critic은 분포 아래에 어디서나 1의 norm을 가진 gradient를 가지고 subsection 2.3 사이의 지역의 큰 부분에 있기 때문에 critic을 너무 구속하지 않는 것처럼 보인다. 우리의 초기의 관찰에서 우리는 이것이 조금 더 좋게 수행한다는 것을 발견했지만, 우리는 이것을 완전히 조사하지는 않는다.

# 5. Experiments

![3](https://user-images.githubusercontent.com/37301677/154640863-3acfc141-e8a9-4a14-b95f-d9ced45856b7.PNG)
![4](https://user-images.githubusercontent.com/37301677/154640870-82058d84-6722-4ebe-8bff-20090f1819a4.PNG)
![5](https://user-images.githubusercontent.com/37301677/154640872-52b32435-14af-4a4d-bc9b-34c1e58a6b08.PNG)

 

# 6. Conclusion

본 연구에서, 우리는 WGAN에서 weight clipping의 문제를 증명하고 같은 문제를 겪지 않는 critic loss에서 penalty term의 형식으로 대체하는 것을 소개했다. 우리의 방법을 사용하여, 우리는 다양한 아키텍쳐에 걸쳐 더 강한 모델링 성능과 안정성을 증명했다. 우리가 GAN을 학습시키기 위해 더 안정적인 알고리즘을 가지고 있으므로, 우리는 우리의 연구가 큰 이미지 데이터셋과 언어에서 더 강한 모델링 성능의 길을 여는 것을 희망한다. 또 다른 흥미로운 방향은 보통의 GAN의 목적 함수에 우리의 penalty term을 적용하는 것이고, 이것은 discriminator가 더 부드러운 결정 경계를 학습하도록 격려되어 학습을 안정화시킬 수 있다.







<br>



지금까지 WGAN-GP 논문 리뷰를 해보았습니다. 저도 논문을 읽으며 공부해나가는 단계라 부족한 점이 있을 수 있습니다. 같이 잘 공부해나가요! 질문이나 지적, 요청해주실 부분이 있다면 댓글이나 메일 부탁드립니다.

읽어주셔서 감사합니다. 😃

